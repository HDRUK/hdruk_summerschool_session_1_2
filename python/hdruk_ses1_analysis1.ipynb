{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health data analysis session\n",
    "\n",
    "In this session, we will investigate how to use Python and its libraries to load, inspects, visualise, and analyse a dataset. The dataset used is concerned with the prediction of strike in a number of patients. The dataset was downloaded from kaggle (https://www.kaggle.com/asaumya/healthcare-problem-prediction-stroke-patients). \n",
    "\n",
    "Within this session, we will load Python libraries which are used throughout the session.\n",
    "\n",
    "Python allows to rename libraries. It is common to do that for the most used libraries, such as pandas (pd) numpy (np) and others. Some libraries are structured using sub-libararies and have to be importated separately (sklearn.decomposition). To have access to the methods at a later stage we will use the full path of the libary and the method (sklearn.decomposition.PCA). \n",
    "\n",
    "\n",
    "```python\n",
    "import sklearn.decomposition\n",
    "...\n",
    "pca_on_train = sklearn.decomposition.PCA(...)\n",
    "```\n",
    "\n",
    "However, it is also possible to only load particular parts (objects and methods) from a library. So, the following is also possible:\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "...\n",
    "pca_on_train = PCA(...)\n",
    "\n",
    "```\n",
    "Both are equivalent. For readability of the code, we have used both variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/downloads/healthcare-dataset-stroke-data.zip/1\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd # data processing, reading files \n",
    "import matplotlib.pyplot as plt # plotting and visulisation\n",
    "import seaborn as sns # nicer (easier) visualisation\n",
    "#import sklearn, sklearn.decomposition, sklearn.manifold, sklearn.compose, sklearn.tree, sklearn.ensemble, sklearn.metrics\n",
    "import IPython.display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to write own scripts, libaries, etc. and load them. Here, a small helper library is loaded. This libary is later used for some encodings and plotting. \n",
    "\n",
    "Furthermore, we switch off warnings within this Jupyter notebook. This is purely for esthetic reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own mini- library\n",
    "import session_helpers\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up local paths\n",
    "\n",
    "To load the data, we set up the local path on the system and use pandas (here pd) to load the data into an object of type DataFrame (from teh library pandas). The data is supplied in CSV file format (csv - comma separated values) in the sub-directory called 'healthcare-dataset-stroke-data'. Other intput types are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data paths, loading data\n",
    "\n",
    "data_dir = './session1_data/healthcare-dataset-stroke-data'\n",
    "file_name_train = 'train_2v_lc.csv'\n",
    "file_name_test  = 'test_2v_lc.csv'\n",
    "\n",
    "# load the data and store it\n",
    "df_train_org = pd.read_csv('{}/{}'.format(data_dir,file_name_train))\n",
    "df_test_org  = pd.read_csv('{}/{}'.format(data_dir,file_name_test))\n",
    "\n",
    "# use these datasets for the initail analysis\n",
    "df_train = df_train_org.copy()\n",
    "df_test  = df_test_org.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a quick look of what attributes (features,columns) are present in the dataset, one can use the method ``` <<DatafRameName>>.columns.values```. Here, we save these values for later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns_train = df_train.columns.values\n",
    "original_columns_test  = df_test.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the data. there are a number of methods. ```head()``` allows one so see the first 5 rows of the dataset. When an optional integer ```n``` is supplied, the first ```n``` rows are shown. \n",
    "```info()```displays the different data types for each column and the number of valied values for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also only access selected columns in the data. By supplying the additional parameter ```column_name```. only the named colums is referenced. The format is ```<<DataFrameName>>[<<ColumnName>>]```. To only access the columns gender and only list the first 10 rows of the data the command would be\n",
    "\n",
    "```python\n",
    "df_train['gender'].head(5)\n",
    "```\n",
    "\n",
    "It is also possible to supply a list of column names. Lists are written with ```[``` and ```]```. As an example, \n",
    "```python\n",
    "df_train[['age','gender']].head(5)\n",
    "```\n",
    "\n",
    "A single column is the special data type ```Series```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['gender'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual columns can be addressed and other methods can be called. This includes ```mean()```, ```sum()```, ```add()```and many more. See the description of the DataFrame object on the pandas web page: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "\n",
    "Try to get the average (```mean```) for the column 'age' from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```describe``` will give a summary of all numerical attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns have missing data. Have a look at the first few entries of the attribute ```smoking_status```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['smoking_status'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some method function can be chaned, depending on the return value. The function ```isnull()``` returns all rows in which a ```Null``` value occurs. These are the rows which are essentially empty. Using the function ```sum()``` will sum up every row. Chaining both will return the number of missing entries within a column. Try get the number of missing entries in the column ```smoking_status```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['smoking_status'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be applied to the complete dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the percentage of missing values for the complete dataset (datframe object), one can simply divide each entry by the length of the dataset. The length of nearly all list-like objects in python is access via the ```len(...)```method. The dots indicate, that the object one would like to know the length of has to be a a parameter of length. The call:\n",
    "\n",
    "```python\n",
    "df_train.isnull().sum()/len(df_train)*100\n",
    "``` \n",
    "will give the relative frequency. The returned list can be sorted using the function ```sort_values(ascending=False)```. You will have to be put brackets ```(<<expression>>)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train.isnull().sum()/len(df_train)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the same for test dataset (```df_test```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_test.isnull().sum()/len(df_test)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot the percentages of missing values as a small graph. Here, we first save the results of the previous task in a variable called ```percentage_missing_train```.\n",
    "\n",
    "The method used is ```<<Series>>.plot.bar()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_missing_train = (df_train.isnull().sum()/len(df_train)).sort_values(ascending=False)\n",
    "percentage_missing_train.plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the distribution of numerical variables, one can use a similar function: ```<<Series>>.plot.hist()``` which can be used to a histogram. The optional parameter ```bins=X``` defines the number of bins used. You might want to try out different values, e.g. ```plot.hist(bins=25)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bmi'].plot.hist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn version\n",
    "In the previous box we used the build-in plot function of pandas. There are other libraries with more options for plotting and slightly pretier results. One of them is called seaborn (https://seaborn.pydata.org). We loaded the library using the name ```sns``` at the beginning of the session. In the following example, we use seaborn to plot BMI again. Seaborn does not automatically ignores missing values. Hence, we have to filter them out using the function ```dropna()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_test['bmi'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a small function which displays the distributions of numerical and categorical variables. It can simply be called by ```session_helpers.plot_histograms(<<dataframe>>)``` with optional parameters ```graph_per_row``` (default=3) and ```max_unique``` (default=50). Attributes which seem to be IDs are filtered out. The method will take a few seconds to complete. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_helpers.plot_histograms(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualisations\n",
    "\n",
    "### Boxplots\n",
    "\n",
    "The target variable in this dataset is stroke. So, we can also have a first look at some of the numerical attributes and their correlation to stroke. \n",
    "\n",
    "First we simply plot boxplots for the two classes of `stroke`.  \n",
    "\n",
    "Please note, that ususally one would standardise the data beforehand (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([df_train['stroke'],df_train[['age','avg_glucose_level','bmi']]],axis=1)\n",
    "\n",
    "\n",
    "plot_data_melt = pd.melt(plot_data,id_vars=\"stroke\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"features\", y=\"value\", hue=\"stroke\", data=plot_data_melt)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, there seems to be a larger number of patients outside the normal confidence intervals for both `bmi`and `avg_glucose_level`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violoinplots\n",
    "\n",
    "Violoinplots can sometimetimes capture the distribution visually better as they plot the distribution of the attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"stroke\", data=plot_data_melt,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Joint distributions\n",
    "\n",
    "Another way is to compare different attributes against eachother. For this one can use jointplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(plot_data['age'], plot_data['bmi'], kind=\"regg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this does not really highlicht the difference between the distribution for stroke itself. We can split the data according to the target column. There are nicer programming version for this, but this will work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_stroke_0 = plot_data[plot_data['stroke']==0]\n",
    "data_X_stroke_1 = plot_data[plot_data['stroke']==1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the jointplot on both splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data_X_stroke_0['age'], data_X_stroke_0['bmi'], kind=\"regg\")\n",
    "sns.jointplot(data_X_stroke_1['age'], data_X_stroke_1['bmi'], kind=\"regg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does one see? \n",
    "\n",
    "Experiement with other combination, like `age` and `avg_glucose_level` or with `bmi` whether there are other interesting observations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values: BMI\n",
    "\n",
    "Not all patients have a BMI value assigned. Two simple ways to overcome this are:\n",
    "a) filter out all patient rows with missing values\n",
    "b) fill the missing ones with the average value of the other data. \n",
    "\n",
    "More complex approaches to deal with missing data exist. \n",
    "\n",
    "For simplicity of the session, we will use simple approach of filling the missing values with the mean. But, please note the difference in the resulting distribution:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_test['bmi'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filling the missing cells with the average value of all other rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple\n",
    "# take mean of bmi\n",
    "df_train['bmi'] = df_train['bmi'].fillna(df_train['bmi'].mean())\n",
    "df_test['bmi'] = df_test['bmi'].fillna(df_test['bmi'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at the same information again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['bmi'][df_train['bmi'].notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values: smoking status\n",
    "BMI was not the only attribute with missing values. The smoking status of a large number of patients was missing. Again, one could ignore all patients without this information or one could fill it. As this is a categorical value it is hard to now with what to fill it for each individual patient. One could fill it, resembling the same distribution like the rest of the data. However, this would be very much random. The approach taken here is to fill it with another categorical value, ```missing```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing smoking status\n",
    "df_train['smoking_status'] = df_train['smoking_status'].fillna('missing')\n",
    "df_test['smoking_status'] = df_test['smoking_status'].fillna('missing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the differences now we can plot the distribution of categorical values. \n",
    "\n",
    "Here, we make two plots: one for counts if patients did not have a stroke and one for patients having had a stroke. We also use different bars for the different genders in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='smoking_status',kind='count',col='stroke',hue='gender',data=df_train,palette=\"Blues_d\",)\n",
    "#sns.catplot(x='smoking_status',kind='count',col='stroke',hue='gender',data=df_train[df_train['stroke']==1],palette=\"Blues_d\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general word on imputation of any sort: overall it is a guess. So, to be conservative probably the best is to filter out columns with a large number of missing values or examples with missing values. \n",
    "\n",
    "In this particular case, as with BMI, it would probably best to filter out patients with missing BMI as the dataset is comparatively large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Categorical Variables\n",
    "\n",
    "Not all modelling algorithms can easily cope with categorical data. Within this section we will map categorical to  numerical ones. \n",
    "\n",
    "As an example, one could map \n",
    "\n",
    "| smoking_status | smoking_status_mapped |\n",
    "| ------------- |:-------------:|\n",
    "| never      | 0 |\n",
    "| formerly      | 1 |\n",
    "| smokes      | 2 |\n",
    "| missing      | 3 |\n",
    "\n",
    "However, one problem with this approach is that numerical values have a inherent ordinal meaning. e.g. if one would like to know how similar ```'formerly'``` to ```'smokes'``` or ```'never'``` to ```'smokes'``` one would after mapping compare 1 to 2 or 0 to 2. For algorithms, these are different meaning. \n",
    "\n",
    "One approach is to encode this into the so called one-hot encoding. Here, one would create an additional variable for each of the possible values. The mapping would look like the following:\n",
    "\n",
    "| smoking_status | smoking_status__never | smoking_status__formerly | smoking_status__smokes | smoking_status__missing |\n",
    "| ------------- |:-------------:|:-------------:|:-------------:|:-------------:|\n",
    "| never      | 1 | 0 | 0 | 0 | \n",
    "| formerly      | 0 | 1 | 0 | 0 | \n",
    "| smokes      |  0 | 0 | 1 | 0 | \n",
    "| missing      |  0 | 0 | 0 | 1 | \n",
    "\n",
    "For simplicity in the later session, we will use both approaches. But, please keep in mind that some of the results should be taken with a pinch of salt, when using the simply mapped version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define categorical colums in form of a list and than use a small function converting all categorical values into one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Variables\n",
    "\n",
    "# define the categorical colums in form of a list\n",
    "cat_columns = ['gender','ever_married','work_type','residence_type','smoking_status']\n",
    "\n",
    "# convert to one-hot-encoding later on\n",
    "# this uses a helper function from the session libaray\n",
    "df_train_enc, df_test_enc = session_helpers.df_one_hot(df_train,df_test,cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply convert the categorical values to numerical values. Here, we will use an object type called encode. To be able to convert the data back into the original values, we keep the values in a so-called dictionary (or hash).\n",
    "\n",
    "```python\n",
    "encoders = {}\n",
    "```\n",
    "\n",
    "Afterwards we loop through each categorical column, create an `LabelEncoder`, fit (and apply) it to the trainining data. Furthermore, we apply the same transformer to the potential test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert to numerical \n",
    "encoders = {}\n",
    "for cat_column in cat_columns:\n",
    "    encoders[cat_column] = LabelEncoder()\n",
    "    df_train[cat_column] = encoders[cat_column].fit_transform(df_train[cat_column])\n",
    "    df_test[cat_column]  = encoders[cat_column].transform(df_test[cat_column])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the encoded data back into the original using the `inverse_transform` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['gender'].inverse_transform(df_train['gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['residence_type'].inverse_transform(df_train['residence_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the encoded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of attributes\n",
    "\n",
    "Using the encoded data, we can have a look and the correlation of each of the valiables using Pearson correlation.\n",
    "\n",
    "```python\n",
    "df_train.corr('pearson')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.corr('pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the correlations\n",
    "\n",
    "A better view of the correlation is to plot it. In the following section, we will use seaborns's `heatmap`  function. Before suing it, we set up a different color palette and configure the plotting size. Both, the palette and the so-called axis of the figure are passed as optional paramteres to the heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different color mapping for plotting\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# define size of the plot\n",
    "fig, ax = plt.subplots(figsize=(9.5, 7))\n",
    "\n",
    "# plot corelation as heatmap\n",
    "sns.heatmap(df_train.corr('pearson'),ax=ax,cmap=cmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we have created a version of the dataset using one-hot encoding (`df_train_enc`). Use this  to plot the correlation in the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different color mapping for plotting\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "column_order = ['id','gender__female','gender__male','gender__other','age','hypertension','heart_disease','ever_married__no','ever_married__yes','work_type__children','work_type__govt_job','work_type__never_worked','work_type__private','work_type__self_employed','residence_type__rural','residence_type__urban','avg_glucose_level','bmi','smoking_status__formerly','smoking_status__missing','smoking_status__never','smoking_status__smokes','stroke']\n",
    "\n",
    "\n",
    "# define size of the plot\n",
    "fig, ax = plt.subplots(figsize=(9.5, 7))\n",
    "\n",
    "sns.heatmap(df_train_enc[column_order].corr('pearson'),ax=ax,cmap=cmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "A common way to have a first glance at a dataset is also to plot it. Obviously, the dataset has far more dimensions as the two ususally used for plotting. Apart from the hsitogram and boxplots eralier, once can use dimensionality reduction methods, trying to capture the essence of the data and to redraw it in two dimensions. \n",
    "\n",
    "In general, the aim is to find a mapping, such that the distance between objects in the original dimensions is preserved in the lower dimension embedding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "One common method is using principle component analysis (PCA). Essentially, PCA can be used for a linear transformation, essentially a translation and rotation of the original data into another coordinate system. PCA will take the axis with the highest variance as first axis, the one with the second hisghest one as second etc. By just using the first two axis, one can plot the dataset in the new coordinate system. \n",
    "\n",
    "In the following section, we break up the code in more mangable bits. We will store the new coordinates within the dataset. To not change the original dataframe, we create a copy of it and work on this copy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of the dataframes\n",
    "df_train_pca = df_train_enc.copy()\n",
    "df_test_pca  = df_test_enc.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define which attributes (columns) to use. We do that indirectly but initially defining the ones not to use and store them as a `set`. Object of Python set type can easily be used to construct unions, intersections etc. \n",
    "\n",
    "As sets have no inherent order, when printing, we sort the set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_not_to_use = set(['id','stroke'])\n",
    "\n",
    "columns_to_use = set(df_train_pca.columns.values)-columns_not_to_use\n",
    "\n",
    "# alternatively - define manually\n",
    "#columns_to_use = ['age','avg_glucose_level','bmi'] # 'heart_disease','hypertension'\n",
    "\n",
    "sorted(columns_to_use)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA depends on the data used to be of the same magnitute. Usually, this is not the case with real world data. Therefore, the data needs to be standardised, i.e. by normalising it to its means and unit variance. \n",
    "\n",
    "Here, we broke done the individual steps into multiple commands, to be able to store the scaler and the PCA model separately. This allows us to apply the same modifications to the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# define the scaling object. StandardScaler does the required scaling for each of the columns individually. \n",
    "scaler_on_train = StandardScaler().fit(df_train_pca[columns_to_use])\n",
    "\n",
    "# define a PCA object with maximum number of dimensions of 10 \n",
    "pca_on_train = PCA(n_components=10)\n",
    "\n",
    "# fit the PCA to the trining data\n",
    "pca_on_train.fit(scaler_on_train.transform(df_train_pca[columns_to_use]))\n",
    "\n",
    "# store the transformed data in train_pcs. \n",
    "train_pca = pca_on_train.transform(scaler_on_train.transform(df_train_pca[columns_to_use]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting data object is of a different type (numpy.ndarray). i.e. not a Pandas DataFrame or Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To insert the new coordinated into it into our (copied) dataset, we just copy the first colum as `pca_1`and the second colummn as `pca_2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca['pca_1'] = train_pca[:,0] # take first column\n",
    "df_train_pca['pca_2'] = train_pca[:,1] # take second column\n",
    "df_train_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. and finally, we can plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='pca_1',y='pca_2',hue='stroke',data=df_train_pca,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate if the test dataset would behave similary, we can now apply the same transformations to the test dataset. Please note, that the test dataset does not have the stroke information. Hence, we cannot use this for coloring the individual samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same scaling and the same PCA transormation to the test data\n",
    "test_pca = pca_on_train.transform(scaler_on_train.transform(df_test_pca[columns_to_use]))\n",
    "\n",
    "# again take only the first two new dimensions\n",
    "df_test_pca['pca_1'] = test_pca[:,0] # take first column\n",
    "df_test_pca['pca_2'] = test_pca[:,1] # take second column\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='pca_1',y='pca_2',data=df_test_pca,ax=ax,color=\".1\") #  marker=\"o\",s=50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visulise both datasets together, we just have to plot both in the same figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='pca_1',y='pca_2',data=df_test_pca,ax=ax,color=\".1\") #  marker=\"o\",s=50\n",
    "sns.scatterplot(x='pca_1',y='pca_2',hue='stroke',data=df_train_pca,ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there do not seem to be extreme outliers in the test data. This is jsut an estimate using PCA. Obvioulsy, one would have to check that in more detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot importance of each new dimension\n",
    "An added bonus of PCA is, that we can measure how much each new dimension can explain the varience in the data. For this we can use the `explained_variance_` in the fitted PCA object. Here, we immediatly plot the results as a percentage. \n",
    "\n",
    "How much of the varience can be explained using only the first two diemnsions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot importance of each principle component:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9.5, 7))\n",
    "ax.set_xlabel(\"PCA #\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "pd.Series(pca_on_train.explained_variance_/pca_on_train.explained_variance_.sum()*100).plot.bar(ax=ax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE\n",
    "\n",
    "tSNE (t-distributed Stochastic Neighbor Embedding) is a tool to visualise high dimensional data. It converts similarities between data points to joint probabilities. It first initialises using either random values or values from a PCA. Depending on the initialisation, each run will result in different embeddings. Furthermore, it does not construct a general model, which can be appllied to unseen data (test data). Hence, it should only be used for visulisations not as a standard diemnsionality reduction method. For more options and explanations, please see https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html and http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\n",
    "\n",
    "tSNE does not atomatically calculate the most important new dimaensions, so one has to supply the desired dimension as a parameter. Furthermore, it optimises the embeddings iteratively. The number of iterations are controlled by supplying an additional parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE on the training data\n",
    "\n",
    "For speed, we use only a smaller set of attributes (columns). Please feel free to play around with other settings. Please note that tSNE uses pairwise distances and can use different metrics. The default is the Euclidean distance.   \n",
    "\n",
    "When using *only* one-hot encoded data, one could use the Jaccard distance (see next section).\n",
    "\n",
    "The embedding will take a while to complete. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# using tSNE\n",
    "\n",
    "# make a copy of the dataset again\n",
    "df_train_tsne = df_train_enc.copy()\n",
    "\n",
    "# define which columns to us - please note that only real numerical values should be used \n",
    "# Encoded ones might be giving wrong results\n",
    "# still, here is a list of possible attributes:\n",
    "# columns_to_use = ['gender', 'age', 'hypertension', 'heart_disease','ever_married', \n",
    "#     'work_type', 'Residence_type', 'avg_glucose_level','bmi', 'smoking_status']\n",
    "\n",
    "columns_to_use = ['age', 'avg_glucose_level','bmi']\n",
    "\n",
    "\n",
    "# create tSNE object. The minimum number of iterations is 250. \n",
    "tsne_on_train = TSNE(n_components=2,n_iter=750)\n",
    "\n",
    "# as tSNE does not learn a model that can easily applied to new data, we use the `fit_transform` funtion directly. \n",
    "train_tsne = tsne_on_train.fit_transform(df_train_tsne[columns_to_use])\n",
    "\n",
    "# again copy the respective columns into the copy of the dataset\n",
    "df_train_tsne['tsne_1'] = pd.Series(train_tsne[:,0])\n",
    "df_train_tsne['tsne_2'] = pd.Series(train_tsne[:,1])\n",
    "\n",
    "# and plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='tsne_1',y='tsne_2',hue='stroke',data=df_train_tsne,ax=ax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE on one-hot encoded data\n",
    "\n",
    "This is only an impression. Potentially, one would have to treat each semantically dependend part (living, smoking, etc.) separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tsne = df_train_enc.copy()\n",
    "\n",
    "# just use columns originating from one-hot encoding (they all have a `__` in their names)\n",
    "columns_to_use = [x for x in list(df_train_tsne.columns.values) if '__' in x]\n",
    "\n",
    "\n",
    "# same as above\n",
    "tsne_on_train = TSNE(n_components=2,n_iter=350,metric='jaccard')\n",
    "train_tsne = tsne_on_train.fit_transform(df_train_tsne[columns_to_use])\n",
    "\n",
    "\n",
    "df_train_tsne['tsne_1'] = pd.Series(train_tsne[:,0])\n",
    "df_train_tsne['tsne_2'] = pd.Series(train_tsne[:,1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='tsne_1',y='tsne_2',hue='stroke',data=df_train_tsne,ax=ax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "It can also be useful to cluster the dataset. Here we use simple k-means and plot the PCA-embedded data. There are a number of different cluserting techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "\n",
    "columns_not_to_use = set(['id','stroke',''])\n",
    "columns_to_use = set(df_train.columns.values)-columns_not_to_use\n",
    "\n",
    "# alternatively - define manually\n",
    "#columns_to_use = ['age','avg_glucose_level','bmi'] # 'heart_disease','hypertension'\n",
    "\n",
    "# k-means\n",
    "number_of_clusters = 3\n",
    "kmeans_model = KMeans(number_of_clusters) #\n",
    "train_cluster_labels = kmeans_model.fit_predict(df_train[columns_to_use])\n",
    "\n",
    "# put cluster labels into the dataframe with PCA dimesnions\n",
    "df_train_pca['cluster_kmeans'] = train_cluster_labels\n",
    "\n",
    "#plot \n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.scatterplot(x='pca_1',y='pca_2',hue='cluster_kmeans',data=df_train_pca,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please do not execute - running time too high\n",
    "\n",
    "\n",
    "# spectral clustering\n",
    "#number_of_clusters = 3\n",
    "#spectral_model = SpectralClustering(number_of_clusters) #\n",
    "#train_cluster_labels = spectral_model.fit_predict(df_train[columns_to_use])\n",
    "\n",
    "# put cluster labels into the dataframe with PCA dimesnions\n",
    "#df_train_pca['cluster_spectral'] = train_cluster_labels\n",
    "\n",
    "#plot \n",
    "#fig, ax = plt.subplots(figsize=(12, 10))\n",
    "#sns.scatterplot(x='pca_1',y='pca_2',hue='cluster_spectral',data=df_train_pca,ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prediction models\n",
    "\n",
    "Here, we will take a sneak preview of some of the approaches presented in a later session originating from machine learning. Please note, that this is not a general introduction of how to validate models or on how to use different algorithms. \n",
    "\n",
    "To estimate the correct parameters of a model, a k-fold cross validation would have to be performed (or similar) and the results would need to be propperly validated (again in some form of cross validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "The most simple validation procedure is the train/test split. In this approach, entries in the data are randomly divided into training and test data. Common split is 70%/30%. As this is done randomly, each time the split is performed two different dataset are generated. Hence, each split will result in a different mnodel and different results. Nevertheless, for a first glimpse that should be fine for the scope of this session.\n",
    "\n",
    "Here we use the `train_test_split`function of sklearn. All predictive models in sklearn require the data to be split into X (the data to train on) and y the target values. In our case, this is stroke. Fruthermore, we remove the ID from the training data, as it should not have any information of the patient encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# simple train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','stroke'],axis=1),df_train['stroke'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision trees\n",
    "\n",
    "The first simple model we will us is a descision tree model (https://scikit-learn.org/stable/modules/tree.html). \n",
    "\n",
    "Descision trees partition the dataset acording to values contain the the attributes. Each example is than passed to the branch corresponding to the answer of the logical test. This is repeated until a leaf node is reached and the majority class within the leaf is predicted. \n",
    "\n",
    "An example tree can be seen here:\n",
    "\n",
    "![title](img/dtree_example.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# create a descision tree object. Here only some options are used. \n",
    "dtree = DecisionTreeClassifier(min_samples_split=5, max_depth=3)\n",
    "# fit the model\n",
    "dtree.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute importance\n",
    "\n",
    "Descision trees can also be employed to estimate the importance of each of the attributes. The importance is calculated by counting how often an attribute is used with in the tree. \n",
    "\n",
    "In the following we are using\n",
    "\n",
    "```python\n",
    "dtree.feature_importances\n",
    "```\n",
    "\n",
    "to assess the importance. The results is plotted using DataFrame as a base object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_feature_importance = pd.DataFrame(dtree.feature_importances_*100,index=list(df_train.drop(['id','stroke'],axis=1)))\n",
    "dtree_feature_importance.plot.bar(legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visulisation of the tree\n",
    "\n",
    "The tree can also be visualised. This could give a first hint at how a prediction is made. \n",
    "\n",
    "Please note: To visualise the tree there are built in methods. Here, we use a combination of built-in methods and own casting of the image. This overcome some problems in the current `plot_tree` implemantation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visulisation:\n",
    "image = session_helpers.plot_tree(dtree,X_train,y_train,rotate=False,max_depth=None)\n",
    "IPython.display.Image(image)\n",
    "\n",
    "# sklearn has its own plot_tree function. But, the rotate parameter seems to be ignored\n",
    "#fig, ax = plt.subplots(figsize=(18, 10))\n",
    "#dtree_text = tree.plot_tree(dtree,filled=True,max_depth=4,fontsize=8,rotate=True,ax=ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat tree building\n",
    "\n",
    "The initial setting for the decision tree was to only construct a tree with maximum depth of 3. This is given the data not enough. Please go back to the box for constructing the tree, and experiemt with different seeting, e.g. 4, 7, or 10 or even `None` (None indicates that not limit should be used). For plotting, you might want to change the parameter rotate to True: \n",
    "```python\n",
    "rotate=True\n",
    "```\n",
    "So, please experiment a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model\n",
    "\n",
    "To establish how well the model is performing, we can now predict the data from the train-test split. The performace of the model should give a rough estimate of how well the model is performing on unseen data. Our original test set does not contain the target variable, so we cannot use it to evaluate the model performance. \n",
    "\n",
    "A simple way is to look at accuracy, precision, and recall. Accuracy measures how many correct predictions were made. Here, we define that that a patient having a stroke (`stroke=1`) is called a positive example and no stroke are nagtives. Prescision (also called positive predictive value) measures how many of the positive prediction made were correct, while recall (also called sensititvity) measure the fraction of positive examples predicted correctly out of all positive examples. \n",
    "\n",
    "An overview of these definitions can also be found here: https://en.wikipedia.org/wiki/Confusion_matrix .\n",
    "\n",
    "So, how well did the model perform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "y_train_predicted = dtree.predict(X_train)\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_train,y_train_predicted)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_train,y_train_predicted)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_train,y_train_predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the same with the test split (`X_test` and `y_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = dtree.predict(X_test)\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_test,y_test_predicted)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_test,y_test_predicted)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_test,y_test_predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance seems to be good in terms of accuracy, but really insufficient for both precsion and recall. Accuracy is not a surprice, as most examples in the dataset are negative. Hence, just prediction negatives would give us already a very good performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves\n",
    "\n",
    "A better way to assess the performance of a classifier is to use Receiver Operating Characteristics curves. In general, they plot the rate of true positives versus the false positive rate. To achieve this, all predictions are assumed to predict positive and are sorted to some score, mostly a probability. The resulting list goes from the most likely correct prediction to the least likely and assess whether or not it was a triu positve. \n",
    "\n",
    "The area under the ROC curve is also used as a measure of performance. A perfect model would have the area of 1.0. A random model the area of 0.5. \n",
    "\n",
    "Let us asses the performance of the decsion tree. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_train_predicted_proba = dtree.predict_proba(X_train)[:,1]\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_train,y_train_predicted_proba)\n",
    "auc_score = auc(fpr,tpr)\n",
    "print('AUC:  {:3.8f}'.format(auc_score))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = {:.2f})'.format(auc_score))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with unbalenced data\n",
    "\n",
    "### Up/Downsampling\n",
    "\n",
    "One way to get a better model, is to upsample the positive examples or to downsample the negatives ones. This can be done using the `RandomOverSampler` in the imblearn libarary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# upsample\n",
    "random_sampler = RandomOverSampler(random_state=0)\n",
    "#X_resampled,y_resampled = random_sampler.fit_resample(df_train.drop(['id','stroke'],axis=1),df_train['stroke'])\n",
    "\n",
    "X_resampled,y_resampled = random_sampler.fit_resample(X_train,y_train)\n",
    "\n",
    "# simple train and test split\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_resampled,y_resampled)\n",
    "\n",
    "# create a descision tree object. Here only some options are used. \n",
    "dtree_r = DecisionTreeClassifier(min_samples_split=5, max_depth=10)\n",
    "# fit the model\n",
    "dtree_r.fit(X_train_r,y_train_r)\n",
    "\n",
    "y_train_predicted_r = dtree_r.predict(X_train_r)\n",
    "print('Performance on training split (resampled test set)')\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_train_r,y_train_predicted_r)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_train_r,y_train_predicted_r)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_train_r,y_train_predicted_r)))\n",
    "print()\n",
    "\n",
    "y_test_predicted_r = dtree_r.predict(X_test_r)\n",
    "print('Performance on test split (resampled test set)')\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_test_r,y_test_predicted_r)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_test_r,y_test_predicted_r)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_test_r,y_test_predicted_r)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note, that this model will only work on balanced data. Using the model on the original data will perform well, as can be seen in the below boxes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted = dtree_r.predict(X_train)\n",
    "print('Performance on training split (original test set)')\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_train,y_train_predicted)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_train,y_train_predicted)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_train,y_train_predicted)))\n",
    "print()\n",
    "y_test_predicted = dtree_r.predict(X_test)\n",
    "print('Performance on test split (original test set)')\n",
    "print('Accuracy:  {:3.8f}'.format(accuracy_score(y_test,y_test_predicted)))\n",
    "print('Precision: {:3.8f}'.format(precision_score(y_test,y_test_predicted)))\n",
    "print('Recall:    {:3.8f}'.format(recall_score(y_test,y_test_predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted_r_proba = dtree_r.predict_proba(X_train_r)[:,1]\n",
    "\n",
    "\n",
    "fpr_r,tpr_r,thresholds_r = roc_curve(y_train_r,y_train_predicted_r_proba)\n",
    "auc_score_r = auc(fpr_r,tpr_r)\n",
    "print('AUC:  {:3.8f}'.format(auc_score_r))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.plot(fpr_r,tpr_r, color='darkorange', label='ROC curve (area = {:.2f})'.format(auc_score_r))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss with your neighbour, whether this is really the better approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
